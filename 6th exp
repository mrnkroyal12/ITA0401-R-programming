# Load necessary libraries
library(readr)  # For CSV files
library(readxl) # For Excel files
library(jsonlite) # For JSON files

# Define the function
read_and_process_data <- function(file_path) {
  # Detect file format
  file_ext <- tools::file_ext(file_path)
  
  # Read data based on file format
  if (file_ext == "csv") {
    data <- read_csv(file_path)
  } else if (file_ext %in% c("xls", "xlsx")) {
    data <- read_excel(file_path)
  } else if (file_ext == "json") {
    data <- fromJSON(file_path, flatten = TRUE)
    data <- as.data.frame(data)
  } else {
    stop("Unsupported file format!")
  }
  
  # Assess data quality
  missing_count <- sum(is.na(data))
  total_values <- prod(dim(data))
  missing_percentage <- (missing_count / total_values) * 100
  print(paste("Missing values:", missing_count))
  print(paste("Percentage of missing data:", round(missing_percentage, 2), "%"))
  
  # Write cleaned data to a new file (for simplicity, save as CSV)
  clean_file_path <- paste0(tools::file_path_sans_ext(file_path), "_cleaned.csv")
  write.csv(data, clean_file_path, row.names = FALSE)
  
  print(paste("Cleaned dataset saved to:", clean_file_path))
  return(data)
}

# Example usage
# file_path <- "data.json"  # Provide your file path here
# dataset <- read_and_process_data(file_path)
